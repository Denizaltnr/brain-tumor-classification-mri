import streamlit as st
import os
import numpy as np
from PIL import Image
import joblib
from tensorflow.keras.models import load_model
from utils.preprocessing import preprocess_image, flatten_for_classic_models
import streamlit as st
import requests
import zipfile
import os
from pathlib import Path

@st.cache_resource
def download_models():
    """GitHub Releases'dan modelleri indir"""
    models_dir = Path("models")
    
    if models_dir.exists() and any(models_dir.iterdir()):
        return  # Modeller zaten var
    
    models_dir.mkdir(exist_ok=True)
    
    with st.spinner("Model dosyalarÄ± indiriliyor..."):
        try:
            # GitHub Releases API
            api_url = "https://api.github.com/repos/Denizaltnr/brain-tumor-classification-mri/releases/latest"
            response = requests.get(api_url)
            release_data = response.json()
            
            for asset in release_data['assets']:
                if asset['name'].endswith('.zip'):
                    download_url = asset['browser_download_url']
                    
                    # DosyayÄ± indir
                    file_response = requests.get(download_url, stream=True)
                    zip_path = f"temp_{asset['name']}"
                    
                    with open(zip_path, 'wb') as f:
                        for chunk in file_response.iter_content(chunk_size=8192):
                            f.write(chunk)
                    
                    # Zip'i Ã§Ä±kar
                    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                        zip_ref.extractall('models')
                    
                    os.remove(zip_path)
                    st.success("Modeller baÅŸarÄ±yla yÃ¼klendi!")
                    return
                    
        except Exception as e:
            st.error(f"Model yÃ¼kleme hatasÄ±: {e}")
            st.info("LÃ¼tfen manuel olarak model dosyalarÄ±nÄ± yÃ¼kleyin.")

# Ana uygulamanÄ±n baÅŸÄ±nda Ã§aÄŸÄ±r
download_models()

# ğŸ” Model yollarÄ±
MODEL_PATHS = {
    "CNN": "models/cnn_model.h5",
    "VGG16": "models/vgg16_model.h5",  # DÃ¼zeltildi: Ã§ift underscore kaldÄ±rÄ±ldÄ±
    "MobileNet": "models/mobilenet_model.h5",
    "SVM": "models/svm_model.pkl",
    "Random Forest": "models/rf_model.pkl"
}

# ğŸ§  SÄ±nÄ±f etiketleri
class_labels = {
    0: "glioma_tumor",
    1: "meningioma_tumor",
    2: "no_tumor",
    3: "pituitary_tumor"
}

st.set_page_config(page_title="Beyin TÃ¼mÃ¶rÃ¼ SÄ±nÄ±flandÄ±rmasÄ±", layout="centered")
st.title("ğŸ§  Beyin TÃ¼mÃ¶rÃ¼ SÄ±nÄ±flandÄ±rma UygulamasÄ±")
st.write("MRI gÃ¶rÃ¼ntÃ¼sÃ¼ne gÃ¶re tÃ¼mÃ¶r tÃ¼rÃ¼nÃ¼ tahmin eder.")

uploaded_image = st.file_uploader("ğŸ” MRI GÃ¶rselini YÃ¼kleyin", type=["jpg", "jpeg", "png"])
model_choice = st.selectbox("ğŸ“Œ Model SeÃ§in", list(MODEL_PATHS.keys()))

if uploaded_image and model_choice:
    image = Image.open(uploaded_image)
    st.image(image, caption="YÃ¼klenen GÃ¶rsel", use_column_width=True)

    try:
        # ğŸ“¦ Model dosyasÄ±nÄ±n varlÄ±ÄŸÄ±nÄ± kontrol et
        model_path = MODEL_PATHS[model_choice]
        if not os.path.exists(model_path):
            st.error(f"âš ï¸ Model dosyasÄ± bulunamadÄ±: {model_path}")
            st.stop()

        # ğŸ”§ GÃ¶rseli iÅŸle - TÃœM MODELLER Ä°Ã‡Ä°N AYNI BOYUT
        image_array = preprocess_image(image, model_type=model_choice)

        # ğŸ“¦ Modeli yÃ¼kle ve tahmin yap
        if model_choice in ["CNN", "VGG16", "MobileNet"]:
            model = load_model(model_path)
            
            # CNN iÃ§in dinamik boyut kontrolÃ¼ (inference kodundan)
            if model_choice == "CNN":
                expected_shape = model.input_shape[1:3]  # (height, width)
                current_shape = image_array.shape[1:3]
                
                if expected_shape != current_shape:
                    st.info(f"ğŸ”„ CNN boyut uyumsuzluÄŸu: {current_shape} -> {expected_shape}. Yeniden boyutlandÄ±rÄ±lÄ±yor...")
                    # Yeniden boyutlandÄ±r
                    from PIL import Image as PILImage
                    img_resized = PILImage.fromarray((image_array[0] * 255).astype(np.uint8))
                    img_resized = img_resized.resize(expected_shape)
                    image_array = np.array(img_resized) / 255.0
                    image_array = np.expand_dims(image_array, axis=0)
            
            prediction = model.predict(image_array)
            predicted_class = int(np.argmax(prediction))

        elif model_choice in ["SVM", "Random Forest"]:
            model = joblib.load(model_path)
            
            # Model tipine gÃ¶re Ã¶zel flatten
            if model_choice == "SVM":
                # SVM: Grayscale flatten (50,176 features)
                image_array = flatten_for_classic_models(image_array, "SVM")
            elif model_choice == "Random Forest":
                # RF: MobileNet feature extraction
                image_array = flatten_for_classic_models(image_array, "Random Forest")
                
            predicted_class = model.predict(image_array)[0]

            # Klasik modeller string dÃ¶ndÃ¼rÃ¼yor olabilir, sayÄ±ya Ã§evir
            if isinstance(predicted_class, str):
                predicted_class = int(list(class_labels.keys())[list(class_labels.values()).index(predicted_class)])

        class_name = class_labels.get(predicted_class, "Bilinmeyen SÄ±nÄ±f")
        st.success(f"âœ… Tahmin: {class_name}")

    except Exception as e:
        st.error(f"âš ï¸ Tahmin sÄ±rasÄ±nda hata oluÅŸtu: {e}")
        st.info("ğŸ’¡ Model tipine gÃ¶re preprocessing:")
        st.info("â€¢ CNN: RGB, dinamik boyut")  
        st.info("â€¢ SVM: GRAYSCALE, 224x224 (50,176 features)")
        st.info("â€¢ RF: RGB + MobileNet features")
        st.info("â€¢ VGG16/MobileNet: RGB, 224x224")
